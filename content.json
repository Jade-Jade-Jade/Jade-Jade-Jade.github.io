{"meta":{"title":"Jade-Jade-Jade","subtitle":"不忘初心，方得始终","description":null,"author":"Jade-Jade-Jade","url":"http://yoursite.com"},"pages":[{"title":"image","date":"2017-09-17T13:10:25.000Z","updated":"2017-09-18T04:10:25.000Z","comments":true,"path":"image/index.html","permalink":"http://yoursite.com/image/index.html","excerpt":"","text":""}],"posts":[{"title":"比特币的崛起-观后笔记","slug":"比特币的崛起-观后笔记","date":"2017-12-26T07:15:37.000Z","updated":"2017-12-27T04:13:04.000Z","comments":true,"path":"2017/12/26/比特币的崛起-观后笔记/","link":"","permalink":"http://yoursite.com/2017/12/26/比特币的崛起-观后笔记/","excerpt":"","text":"technology must be used to liberate the individual. 很早就听说过Bitcoin(比特币)这一概念但是一直没有深入了解的想法。大概因为我这个老古董对于新生的事物总是心存胆怯，稍微有一点点出格的大变动就觉得地球要毁灭。今天无意间看到了BBC的纪录片-The Rise and Rise of Bitcoin。已经是2014年的老片子了，便决定花半个下午好好观看一下也作为区块链的背景资料。也在博客开了一个区块链的坑，希望以后常种草。 以下是纪录片内容的摘录和整理 比特币(Bitcoin)的由来那个叫中本聪的人发明了比特币，起稿了比特币白皮书。却没有人知道谁是中本聪。 在2008年万圣节，某人用化名中本聪在密码学邮件组发帖。帖子中指向的白皮书提出一种用于互联网的新型支付系统。内容包含使用“点对点网络系统”的协议，工作量证明以及公钥加密。 虽然在这之前的很多年以来，计算机行家们都在尝试用这些技术创造数字货币。但是中本聪创造了这种史无前例的融合方法。所以说他发明了比特币。 比特币(Bitcoin)的发展 中本聪的设计得到了广泛的认可，于是世界的程序员和密码学家开始着手共同发展比特币。在2009年10月,第一个汇率发布了，标记1美元可以兑换1309个比特币。比特币那时候很便宜,而后几年里，它们的兑换交易依旧以美元的分厘计算。 2010年春季,一个叫做赖斯罗(Laszlo)的佛罗里达伙计决定试着用他的比特币买东西，他报价10000枚比特币给那个愿意买披萨给他的人。一个在伦敦的人接受了报价并且打了一个长途电话在Papa John’s家定了两个披萨。人们认为这是首个比特币兑换实物的交易。 为了让比特币兴盛起来，需要更多的人拥有比特币。于是，日本一个叫做“门头沟”的比特币交易所应运而生。比特币交易额开始上升，到2010年11月已挖出的比特币大概四百万枚，交易价格已经到了0.5美元一枚了。市场苏醒，比特币看起来开始有成为货币的潜质了。 在一次25万件政府公文被公布于众后，维基解密的捐款渠道都被切断 - 像美国银行，以及visa和万事达信用卡更不用说贝宝和西联汇款了。一篇在“pc世界”上的文章建议可以利用比特币来给维基解密捐助。中本聪最后发布的一些帖子里就有对于这个文章的回复。他说”要是能任何别的场合下能获得此等关注就好了，维基解密踢翻了马蜂窝，蜂群却向我们扑来”。不久之后，中本聪从论坛中销声匿迹。 两个月后丝绸之路（silk road）建立，它是一个用来交易毒品 以及其他非法东西的黑色市场。只能用比特币，因为比特币让金钱流向基本上不可能得到追踪。 比特币的汇率持续上涨，到了2011年2月份比特币的价格已经到达每枚1美元，这吸引了大量用户以及投机者，到六月的时候，价格暴涨到了31美元，然后突然崩溃了。市场重挫, 门头沟被黑了，在之后很长一段时间里这都打击着投资者的信心，价格一直下跌，到十月份只有2美元左右。 金融危机在塞浦路斯爆发。2013年4月份。欧盟和德国打着反洗钱的幌子，通过对存款人增税的方式来应对塞浦路斯的债务危机。塞浦路斯的储户人人自危，比特币作为去中心化和超主权的网络货币得到了欧洲避险资金的青睐。 塞浦路斯危机发生的同时，美国财政部的监管人员也在思量着比特币。美国金融犯罪执法网络发布了首个对于虚拟货币的监管条例，条例中隐射道就它本身而言,比特币不是非法的。 塞浦路斯事件使人们意识到比特币可以作为一个金融安全的天堂。美国监管者的点头对投资者来说更是亮了绿灯。交易价格继续爬升。比特币开始从非常非常早期的投资阶段进入到相对早期的投资阶段。 Bitinstant 2011年，23岁的Charlie shrem创立了Bitinstant。Bitinstant是比特币界的第一个初创企业。在比特币早期,人们必须辗转很多个地方才能买到它。唯一捷径就是去门头沟交易所了，但这个过程需要在数个中间机构之间汇钱，要花费数周。查理成立Bitinstant为的就是简化这个过程帮人们快速买币。 2014年，Charlie Shrem和他的客户Robert Faiella承认了与无执照货币交换相关的指控。 他们在今年初被捕，被控参与了超过100万美元的比特币交易，检方称他们明知用户购买比特币是去丝绸之路购买毒品。Charlie Shrem被判了两年的牢狱。 不同人士对比特币的看法 美国金融犯罪执法网络的部门人员对于比特币监管条例，表明了看法:如果你是一个用比特币来购买产品和服务的消费者,那么，那监管条例将跟你没关系。它主要是为了防范金融系统里的洗钱以及恐怖主义援助。我觉得肯定–比特币社区里的很多人都担心比特币会被用作不好的用途。它还有很多巨大的潜力，如围绕比特币和虚拟经济的技术革新。比特币在无银行地区确实有很大的潜力能够真的提供方便的服务。但另一方面来看它是金融系统的一部分了，包括全美，全球金融系统的一部分。当然它就得负责任了，责任就包括不让某些机构用它来从事犯罪以及恐怖主义。 纪录片中Mike Caldwell(实体比特币-casascius币)的创造者说:密码学其实能为我们做很多事情,像很多社会问题都能被密码学解决。密码学能给选举带去公正，常人是难以理解密码学的，毕竟大多数人水平不足。 纪录片录制者丹尼尔说:现在我们只通过比特币来发送金钱,但是很多人相信，它的革命性意义不仅如此。比特币背后的技术可以被用来创建无法作假，规定不可改动的去中心化系统。 视频链接 比特币的崛起","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[]},{"title":"Logic之命题逻辑和一阶逻辑","slug":"Logic之命题逻辑和一阶逻辑","date":"2017-10-21T18:42:19.000Z","updated":"2017-10-22T09:52:21.000Z","comments":true,"path":"2017/10/22/Logic之命题逻辑和一阶逻辑/","link":"","permalink":"http://yoursite.com/2017/10/22/Logic之命题逻辑和一阶逻辑/","excerpt":"","text":"该博文是命题逻辑和一阶逻辑的学习笔记，总结了教材和老师讲义。请勿转载。之后可能会附上相关代码。","categories":[{"name":"AI坑","slug":"AI坑","permalink":"http://yoursite.com/categories/AI坑/"}],"tags":[]},{"title":"知识图谱学习1","slug":"知识图谱学习1","date":"2017-10-20T11:01:38.000Z","updated":"2017-10-22T09:38:47.000Z","comments":true,"path":"2017/10/20/知识图谱学习1/","link":"","permalink":"http://yoursite.com/2017/10/20/知识图谱学习1/","excerpt":"","text":"近期上搜索引擎的时候提到了知识图谱这个专题，先开坑。后续慢慢填。","categories":[{"name":"资料检索与搜索引擎","slug":"资料检索与搜索引擎","permalink":"http://yoursite.com/categories/资料检索与搜索引擎/"}],"tags":[]},{"title":"挖坑之非自用着装攻略-男青年","slug":"挖坑之非自用着装攻略-男青年","date":"2017-10-19T14:52:17.000Z","updated":"2017-10-20T05:54:27.000Z","comments":true,"path":"2017/10/19/挖坑之非自用着装攻略-男青年/","link":"","permalink":"http://yoursite.com/2017/10/19/挖坑之非自用着装攻略-男青年/","excerpt":"","text":"我自己本身也很喜欢男装的简洁和大方，逛起来都差不多，不像女孩子的衣服看起来眼花缭乱…鉴于身边男性程序员朋友很多，决定写一个男装搭配的小博文。我希望文章可以让大部分普通的男孩子收益，大长腿大高个身材好的就自己随便搭配吧，感觉都不会丑到哪里去…..— 题记 准则 衣服不要皱不要皱不要皱，不要穿皱皱的外套，皱皱的t恤。 关于衣服皱这个，洗完衣服好好展开。然后买衣服的时候注意一下质量！ 头发不要油. 不用打摩丝什么的，就清清爽爽就好。 脸也不要太油光泛滥了，用些洗面奶就可以，基本的护肤还是需要的我觉得。 背不要弯。 有的男孩子肩膀窄，我不喜欢肩膀窄的男孩穿软塌塌的那种外套。。就显得更窄了没有男友力囧。 建议衣服自己按照一套套的搭配好，或者按照对应的关系搭配。比如自己会清楚的知道买这个裤子有哪些上衣配。这样很节约时间。 品牌推荐一年四季篇https://www.zhihu.com/question/58162135 亮色我发现好多男孩子都喜欢亮色 - 橙色，黄色，蓝色为主！而且都是那种颜色十分纯的！记得以前美术老师和我们说，一般小孩子都很喜欢这种纯度很高的颜色，长大了会喜欢有点灰度的。哈哈哈，如果你喜欢纯色！说明你有个大大的童心:) 知乎里很多帖子都是黑白灰走气质路线。不过我们也不能为了帅气就抛弃自己挚爱的骚气! 我自己觉得纯色是一种很可爱的颜色！尤其是那种平时很正经突然来一个亮色，有一种十分活泼的感觉！ 一般我没见到太多人穿纯彩色的裤子，一般都是外套和t恤占多数。还有骚气外露的各种鞋子。","categories":[{"name":"寻常日","slug":"寻常日","permalink":"http://yoursite.com/categories/寻常日/"}],"tags":[]},{"title":"衣","slug":"衣","date":"2017-10-14T09:53:00.000Z","updated":"2017-10-19T23:21:26.000Z","comments":true,"path":"2017/10/14/衣/","link":"","permalink":"http://yoursite.com/2017/10/14/衣/","excerpt":"","text":"好看的衣服也会让自己开心起来。— 题记 店铺汇集 Urban Outfittershttps://www.urbanoutfitters.com 第一次见到这个牌子是在Harvard Square。和橙子约着一起吃了一顿午饭，饭后开始在Harvard Square周边闲逛。一家很有意思的店面，卖衣服卖鞋帽也卖拍立得还有唱片。 后来又在纽约遇到，才意识到这是一家连锁店。来到洛杉矶，无车的自己开始怀念当时在波屯没事走走停停逛逛街的日子。 网店的种类其实也很多,但是少了一种在实体店淘货的感觉。 百武西淘宝旗舰店链接 初识百武西是在家乡的八佰伴闲逛的时候发现的。扶手电梯的转角。复古文艺的摆设把我一下子就吸引过去。这是个向30年代致敬的生活品牌。它用的模特面目没有棱角分明，身材也没有那么前凸后翘，却一个个就像从书本里缓缓走出来的女学生一般，有着那个年龄独有的精致和年轻。 有天猫京东官网，依旧独爱在店里一件件细细品读。 &amp; Other Storieshttps://www.stories.com/us/Ready-to-wear h&amp;m旗下的品牌。年轻时尚价格亲民。暂时mark还未购买过。 Zara价格迷人也有点时尚，觉得质量没有那么感人。只买过它家一个黑裤子。 Pixie Markethttps://www.pixiemarket.com/ 高街品牌，潮。第一次看到一下心水卖了几件。但是觉得质量对不起价格。不会再买。 DKNYhttps://www.dkny.com/us/sets/clothing-view-all 最新发现的身处奥特莱斯中的好店。 Tommyhttp://usa.tommy.com/en/NEWARRIVALS-WOMEN 性冷淡风 有时候想涂一次红唇，或是买了一个新包，性冷淡风的服装便让这些点缀显得格外的显眼。同时，这又是最好的商务休闲，简单随性大方。 不过觉得，一些性冷淡风风格却不冷淡的衣服更需要在实体店中尝试和搭配。 优衣库在国内的时候我一次都没有买过，也是很奇怪。第一次买它居然是在美国，而且那次一逛就停不下来一次剁手了好多件。我并不算是优衣库的常客，有且只有一次夏装的购买经验。但是也算是给自己种草了这个牌子吧。 Everlanehttps://www.everlane.com/collections/womens-all 自己还没有购买过，但是逛官网的时候觉得不错的样子，价格也不是特别贵。 Coshttps://www.cosstores.com/us/ 第一次试是大四去美国前在合肥某家商场闲逛时被朋友安利的。到了美国才后知后觉的意识到原来是h&amp;m旗下的品牌。好看但是觉得要去实体店试，不大敢直接在网上剁手。 Acne Studioshttp://www.acnestudios.com/us/en/woman/outerwear/ 定价略高，不过看官网确实是我的菜。价位真的有点高啊….要努力…. frankandoakhttps://www.frankandoak.com/women/featured/new-in 鞋子 Kedshttp://www.keds.com/en/home 美帝老北京布鞋替代款….对，我是老北京布鞋脑残粉….","categories":[{"name":"寻常日","slug":"寻常日","permalink":"http://yoursite.com/categories/寻常日/"}],"tags":[]},{"title":"网络爬虫初识 Web-Crawling","slug":"网络爬虫初识","date":"2017-10-02T05:39:17.000Z","updated":"2017-10-03T04:28:31.000Z","comments":true,"path":"2017/10/02/网络爬虫初识/","link":"","permalink":"http://yoursite.com/2017/10/02/网络爬虫初识/","excerpt":"","text":"","categories":[{"name":"资料检索与搜索引擎","slug":"资料检索与搜索引擎","permalink":"http://yoursite.com/categories/资料检索与搜索引擎/"}],"tags":[]},{"title":"去重 De-Duplication","slug":"去重","date":"2017-09-25T12:51:02.000Z","updated":"2017-10-02T21:27:37.000Z","comments":true,"path":"2017/09/25/去重/","link":"","permalink":"http://yoursite.com/2017/09/25/去重/","excerpt":"","text":"定义 De-duplication – the process of identifying and avoiding essentially identical web pages With respect to web crawling, de-duplication essentially refers to the identification of identical and nearly identical web pages and indexing only a single version to return as a search result 对于相同或者相近的网页，只留下一个版本 [例子] the URL’s host name can be distinct (virtual hosts), the URL’s protocol can be distinct (http, https), the URL’s path and/or page name can be distinct 不同的地址指向相同的网站 http://maps.google.comhttps://www.google.com/maps 相类似的网站 比如一个网页前后相隔几秒的版本 镜像 Mirroring is the systematic replication of web pages across hosts.是造成duplicate的一个重要原因 Host1/α and Host2/β are mirrors iff：123For all (or most) paths p such that http://Host1/α/p exists when http://Host2/β/p exists as well with identical (or near identical) content, and vice versa. 例如 https://www.apache.org/dyn/closer.cgi [解释] 在云计算中也经常提到De-duplication的概念，但是与此处所说的并不一样 解决Duplication/Near-Duplication的问题 Duplication[方法] compute fingerprints using cryptographic hashing, 如 SHA-1 和 MD5。有序排列，方便查找logN Near-Duplication[方法] compute the syntactic similarity, and use a similarity threshold to detect near-duplicates 这里具体介绍两种方法 通过计算w-Shingles和Jaccard Similarity来得到相似度 [参考视频] https://www.youtube.com/watch?v=bQAYY8INBxg[视频笔记] 通过fingerprints来计算similarity[SimHash] Simhash is one where similar items are hashed to similar hash values(by similar we mean the bitwise Hamming distance between hash values)1234567891011pick a hashsize, lets say 32 bitslet V = [0] * 32 # (ie a vector of 32 zeros)break the input phrase up into shingles. e.g. &apos;the cat sat on the mat&apos;.shingles(2) =&gt;#&lt;Set: &#123;&quot;th&quot;, &quot;he&quot;, &quot;e &quot;, &quot; c&quot;, &quot;ca&quot;, &quot;at&quot;, &quot;t &quot;, &quot; s&quot;, &quot;sa&quot;, &quot; o&quot;, &quot;on&quot;, &quot;n &quot;, &quot; t&quot;, &quot; m&quot;, &quot;ma&quot;&#125;&gt; hash each feature using a normal 32-bit hash algorithm. e.g. &quot;th&quot;.hash = -502157718 &quot;he&quot;.hash = -369049682 ... for each hash if bit_i of hash is set then add 1 to V[i] if bit_i of hash is not set then take 1 from V[i]simhash bit_i is 1 if V[i] &gt; 0 and 0 otherwise [通过SimHash找到相似的页面] 如果两个SimHash的Hamming distance相近，则如果将所有SimHash有序排列，它们会位于比较相近的位置 数字位左移或者右移相同的位置，其相对Hamming distance不改变因此可以这样做123rotate the bits B times (B is the length of vector) sort check adjancent","categories":[{"name":"资料检索与搜索引擎","slug":"资料检索与搜索引擎","permalink":"http://yoursite.com/categories/资料检索与搜索引擎/"}],"tags":[]},{"title":"搜索引擎的评估 Search Engine Evaluation","slug":"搜索引擎的评估","date":"2017-09-25T06:46:03.000Z","updated":"2017-10-02T20:39:37.000Z","comments":true,"path":"2017/09/25/搜索引擎的评估/","link":"","permalink":"http://yoursite.com/2017/09/25/搜索引擎的评估/","excerpt":"","text":"MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} }); How do we measure the quality of search engines? Recall and Precision（召回率和精确率） $$Precision = \\frac{relevant{\\space}items{\\space}retrieved}{all{\\space}retrieved{\\space}items}$$ $$Recall = \\frac{relevant{\\space}items{\\space}retrieved}{all{\\space}relevant{\\space}items}$$ — Relevant Nonrelevant Retrived True Positive(tp) False Positive(fp) Not Retrived False Negative(fn) True Negative(tn) $$Precision = \\frac{tp}{tp+fp}$$ $$Recall = \\frac{tp}{tp+fn}$$ $$Accuracy = \\frac{tp+tn}{tp+fp+fn+tn}$$ [解释]: 这里的positive相当于积极的评价，也就是retrive；negative表示消极的评价，也就是没有取回。因此true positive表示该判断正确结果确实是相关的，false negative表示该消极的判断错误，结果其实是相关的。 [准确率]: \\(Accuracy = \\frac{tp+tn}{tp+fp+fn+tn}\\) 但是通常我们并不会用准确率来作为评判的标准 [有意思的一段分析]:The advantage of having the two numbers for precision and recall is that one is more important than the other in many circumstances.Typical web surfers would like every result on the first page to be relevant (high precision) but have not the slightest interest in knowing let alone looking at every document that is relevant.在web applications中, Precision is more important than RecallIn contrast, various professional searchers such as paralegals and intelligence analysts are very concerned with trying to get as high recall as possible, and will tolerate fairly low precision results in order to get it.在专业搜索中，我们更关注高的召回率，为了达到这个目的可以忍受相对低的精确度Individuals searching their hard disks are also often interested in high recall searches.硬盘搜索中也期待有高的召回率Nevertheless, the two quantities clearly trade off against one another: you can always get a recall of 1 (but very low precision) by retrieving all documents for all queries! Recall is a non-decreasing function of the number of documents retrieved. On the other hand, in a good system, precision usually decreases as the number of documents retrieved is increased. In general we want to get some amount of recall while tolerating only a certain percentage of false positives.不管怎么说，Precision和Recall是相互牵制的。你总是可以通过取回尽量多的文件来达到高的召回率，比如说每次都取回所有的文件则召回率总是1。但是这时候精确度就很低了。在一个好的系统中，往往精确度随着召回数的增加而降低，不过通常我们忍受一定程度的fp来达到较好的召回率 Pythagorean Mean Arithmetic Mean 算数平均数 $$A=\\frac{1}{n}\\sum_{i=1}^n{x_i}$$ Geometric Mean 几何平均数 $$G = \\sqrt[n] {x_1x_2…x_n}$$ Harmonic Mean 调和平均数 $$H = {(\\frac{\\sum_{i=1}^n{x_i^{-1}}}{n})}^{-1}$$ F Measure weighted harmonic mean of precision and recall $$F = \\frac{1}{\\alpha\\frac{1}{P}+(1-\\alpha)\\frac{1}{R}} = \\frac{({\\beta}^2+1)PR}{\\beta^2P+R}, \\space\\space\\space {\\beta}^2=\\frac{1-\\alpha}{\\alpha} $$ Balanced \\(F_1\\)measure: with \\(\\beta=1\\), \\(F=\\frac{2PR}{P+R}\\) Values of \\(\\beta&lt;1\\) emphasize precision Values of \\(\\beta&gt;1\\) emphasize recall Calculating Recall/Precision at Fixed Positions 上面所介绍的Precision, recall和F measure都是set-based measure。也就是说用于计算unordered set of documents。而典型的搜索引擎所给出的结果是有一定顺序的。这一小节将介绍如何评估ranked results。 Average Precision of the Revelant Documents [例子] Revelant documents = 6 RANK Relevant OR Nonrelevant Recall Precision 1 R 0.17 1.0 2 N 0.17 0.5 3 R 0.33 0.67 4 R 0.5 0.75 5 R 0.67 0.8 6 R 0.83 0.83 7 N 0.83 0.71 8 N 0.83 0.63 9 N 0.83 0.56 10 R 1.0 0.6 Average Precision of the Revelant Documents = (1.0+0.67+0.75+0.8+0.83+0.6)/5 = 0.78 Averaging Across Queries 上面那个例子是一个query，如何评估多个query呢？ [方法一]仿照上面的方法 (所有Revelant Documents的Precision求和)/(Relevant documents的总数目) $$(1 + .67 + .5 + .44 + .5 + .5 + .4 + .43)/8 = 0.55$$ [方法二]Mean Average Precision (MAP)这个方法是research papers中最常用的方法$$MAP=\\frac{\\sum_{q=1}^Q{Avg{P(q)}}}{Q}, \\space\\space Q=number\\space of\\space queries$$$$AvgP(1)=(1.0+0.67+0.5+0.44+0.5)/5=0.62$$ $$AvgP(2)=(0.5+0.4+0.43)/3=0.44$$ $$MAP=(0.62+0.44)/2=0.53$$ 利用MAP评估搜索引擎的缺点： Marco-averaging: Each query counts equally 也就是说每个query的重要度都是一样的 MAP assumes user is interested in finding many revelant documents for each query [不是很懂] MAP requires many relevance judgments in documents collection Discounted Cumulative Gain The premise of DCG is that highly relevant documents appearing lower in a seach result list should be penalized as the graded relevance value is reduced logarithmically proportional to the position of the result.这个方法的基本思想是:如果一个相关文档出现在结果列表中靠后的位置，那么应该给予相应的惩罚。越靠后惩罚越大。 [例子] 基于Precision和Recall方法的局限性。 Should average over large document collection and query ensembles Need human relevance assessments 需要人来判断是否相关，这并不是很可靠的 Assessments have to be binary 对相关性的评价是非黑即白 Heavily skewed by collection/authorship 不同的领域有可能会有不同的结果，不具有普遍性 Non-­relevance-­based measures 搜索引擎也会使用不基于相关性的方法 Click-through on ﬁrst result: Not very reliable if you look at a single click-through … but pretty reliable in the aggregate. Studies of user behavior in the lab A/B testing","categories":[{"name":"资料检索与搜索引擎","slug":"资料检索与搜索引擎","permalink":"http://yoursite.com/categories/资料检索与搜索引擎/"}],"tags":[]},{"title":"倒排索引_Inverted_Indexing","slug":"倒排索引-Inverted-Indexing","date":"2017-09-20T06:24:56.000Z","updated":"2017-09-21T02:13:42.000Z","comments":true,"path":"2017/09/20/倒排索引-Inverted-Indexing/","link":"","permalink":"http://yoursite.com/2017/09/20/倒排索引-Inverted-Indexing/","excerpt":"","text":"Definition of an Inverted indexAn inverted index is typically composed of a vector containing all distinct words of the text collection in lexicographical order (which is called the vocabulary) and for each word in the vocabulary, a list of all documents (and text positions) in which that word occurs 通俗的说: 单词到包括该单词的文档的集合的映射。 注释: 这里的单词可能是被处理过的，一些常用的处理方法有 Case folding: converting all uppercase letters to lower case Stemming: reducing words to their morphological root Stop words: removing words that are so common they provide no information Inverted index 的应用情景 假设有这样一个Query: 1Which plays of Shakespeare contain the words Brutus AND Caesar but NOT Calpurnia? 方法一 暴力搜索先找到所有包含Brutus和Caesar的话剧，再逐字排查，如果含有Caplurnia就删除掉该话剧。 缺点： Too slow 需要很大的空间 不够灵活，不支持其他的操作，比如”Find the word Romans near countrymen” 方法二： Term-Document Incidence Matrix用了 Bit Map 位运算的思想。构建如下矩阵，(t,d)=1代表term t在document d中出现，0代表没有出现。例如： 这样对于上一个查询，只需要 110100 AND 110111 AND 10111 = 100100 所以the two plays matching the query are: “Anthony and Cleopatra”, “Hamlet” 缺点： 需要很大的空间,并且矩阵通常十分稀疏: 123Given 1 million documents and 500,000 terms.The (term x Document) matrix in this case will have size 500K x 1M orhalf-a-trillion 0’s and 1’s. 方法三： Inverted Index在数据结构上我们选择了链表而不是数组，链表的优势在于： Dynamic space allocation Insertion of terms into documents easy There is space overhead of pointers, though this is not too serious Inverted Index的构建如下图所示 应用举例： 1234567891011121314151617181920212223242526272829303132331）Brutus AND Caesar- Locate Brutus in the Dictionary and Retrieve its postings.Brutus: 2-&gt;4-&gt;8-&gt;16-&gt;32-&gt;64-&gt;128- Locate Caesar in the Dictionary and Retrieve its postings.Caesar: 1-&gt;2-&gt;3-&gt;5-&gt;8-&gt;13-&gt;21-&gt;34- “Merge” the two postings and select the ones in common (postings are document ids):Brutus: 2-&gt;4-&gt;8-&gt;16-&gt;32-&gt;64-&gt;128Caesar: 1-&gt;2-&gt;3-&gt;5-&gt;8-&gt;13-&gt;21-&gt;342-&gt;8O(m + n) 复杂度2）Brutus AND Calpurnia AND CaesarBrutus: 2-&gt;4-&gt;8-&gt;16Caesar: 1-&gt;2-&gt;3-&gt;5-&gt;8-&gt;13-&gt;21-&gt;34Calpurnia: 2-&gt;16Merge的顺序要从短到长依次进行Execute the query as (Calpurnia AND Brutus) AND Caesar.INTERSECT(&lt;t1, . . . , tn&gt;) terms ← SORTBYINCREASINGFREQUENCY(&lt;t1, . . . , tn&gt;) result ← postings( first(terms)) terms ← rest(terms) while terms /= NIL and result /= NIL do result ← INTERSECT(result, postings(first(terms))) terms ← rest(terms) return result印象中有算法解决Merge K sorted list复杂度可以到nklogk(n为链表的平均长度）[LeetCode参考: https://leetcode.com/problems/merge-k-sorted-lists/description/]书本并没有采取这种算法可能有原因的：- 在实际情况中这些个链表的长度一点也不平均- 只需要最短的那个链表给merge结束就完事了我们并不需要完完整整的merge。 Skip Pointers 相关视频讲解 目的： speed up the merging of postings 方法解释：如图所示 算法 1234567891011121314151617INTERSECTWITHSKIPS (p1, p2) answer ← &lt; &gt; while p1 /= NIL and p2 /= NIL do if docID(p1) == docID(p2) then ADD(answer, docID(p1)) p1 &lt;- next(p1) p2 &lt;- next(p2) else if docID(p1) &lt; docID(p2) then if hasSkip(p1) and (docID(skip(p1)) &lt;= docID(p2)) then while hasSkip(p1) and (docID(skip(p1) &lt;= docID(p2)) do p1 &lt;- skip(p1) else p1 &lt;- next(p1) else if hasSkip(p2) and (docID(skip(p2)) &lt;= docID(p1)) then while hasSkip(p2) and (docID(skip(p2) &lt;= docID(p1)) do p2 &lt;- skip(p2) else p2 &lt;- next(p2) return answer 适用范围： Index 相对固定 update的次数比较少: Building effective skip pointers is easy if an index is relatively static; it is harder if a postings list keeps changing because of updates. A malicious deletion strategy can render skip lists ineffective. the presence of skip pointers only helps for AND queries, not for OR queries. 问题： How many skip pointers should we add? TradeOff Problem: More skips -&gt; shorter skip span =&gt; more likely to skip. But lots of comparision to skip pointers Fewer skips -&gt; few pointer comparision, but then long skip spans =&gt; few successful skips Simple Heuristic 用Length的平方根: for a postings list of length P, use sqrt{P} evenly-spaced skip pointers. 硬件对速度的影响 Choosing the optimal encoding for an inverted index is an ever-changing game for the system builder, because it is strongly dependent on underlying computer technologies and their relative speeds and sizes. Traditionally, CPUs were slow, and so highly compressed techniques were not optimal. Now CPUs are fast and disk is slow, so reducing disk postings list size dominates. However, if you’re running a search engine with everything in memory then the equation changes again. Phrase Queries 之前所说的inverted index技术是基于Term的，但是在实际运用中我们经常会查询一个短语，而不是单词，比如：stanford university 这里阐述两个方法 方法一： Bi-word indexes (2-grams, 2 shingles)方法介绍 A bi-word (or a 2-gram) is a consecutive pair of terms in some text。比如 “Friends, Romans, Countrymen” 会生成 “friends romans” 和 “romans countrymen” Each of these bi-words is now added to the dictionary as a term。也就是说之前的Term变成了现在的bi-words。 缺点 数量爆炸！Bi-words will cause an explosion in the vocabulary database 短语长度也许大于2。Queries longer than 2 words will have to be broken into bi-word segments 方法二： Positional indexes方法介绍 相比于之前的inverted index, 这里其实就是多记录了一个Term出现的位置位置：123&lt;Term, TotalFrequency&gt; -&gt; &lt;docID, Frequency&gt; 变成&lt;Term, TotalFrequency&gt; -&gt; &lt;docID, Frequency, Positions&gt; 比方说我们要查询 1to be or not to be 现在我们首先找to be, 步骤如下 123451. 找到同时含有to和be两个term的文档。2. 查找两个term在文档中的位置，如果be的位置在to后面一个，那就找到了一个结果比如上面那个图，我们就能找到一个possible match是to: &lt;...;4:&lt;...,429,433&gt;;...&gt;be: &lt;...;4:&lt;...,430,434&gt;;...&gt; 算法 12345678910111213141516171819202122232425POSITIONALINTERSECT(p1, p2, k) answer &lt;- &lt;&gt; while p1 /= NIL and p2 /= NIL do if docID(p1) == docID(p2) then l &lt;- &lt;&gt; pp1 &lt;- positions(p1) pp2 &lt;- positions(p2) while pp1 /= NIL do while pp2 /= NIL do if |pos(pp1) - pos(pp2)| &lt;= k then ADD(l, pos(pp2)) else if pos(pp2) &gt; pos(pp1) the break pp2 &lt;- next(pp2) while l /= &lt;&gt; and |l[0] - pos(pp1)| &gt; k do DELETE(l[0]) for each ps in l do ADD(answer, &lt;docID(p1), pos(pp1), ps&gt;) pp1 &lt;- next(pp1) p1 &lt;- next(p1) p2 &lt;- next(p2) else if docID(p1) &lt; docID(p2) then p1 &lt;- next(p1) else p2 &lt;- next(p2) return answer","categories":[{"name":"资料检索与搜索引擎","slug":"资料检索与搜索引擎","permalink":"http://yoursite.com/categories/资料检索与搜索引擎/"}],"tags":[]},{"title":"【算法导论32】字符串匹配","slug":"【算法导论32】字符串匹配","date":"2017-09-17T13:06:34.000Z","updated":"2017-10-15T03:11:40.000Z","comments":true,"path":"2017/09/17/【算法导论32】字符串匹配/","link":"","permalink":"http://yoursite.com/2017/09/17/【算法导论32】字符串匹配/","excerpt":"","text":"算法导论 32. String Matching恰逢最近在学习搜索引擎，又提及了字符串处理的只是，便想起来读一次算法导论的32章并且留下笔记。日后再总结其他。 书本中介绍了四个方法。分别为： Naive string-matching algorithm (暴力) The Rabin-Karp algorithm Finite automata KMP 笔记如下: 参考: 算法导论以及 https://niuye.info/fms-kmp/","categories":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/categories/算法/"}],"tags":[]},{"title":"不忘初心","slug":"不忘初心","date":"2017-08-11T04:01:47.000Z","updated":"2017-08-14T04:07:54.000Z","comments":true,"path":"2017/08/11/不忘初心/","link":"","permalink":"http://yoursite.com/2017/08/11/不忘初心/","excerpt":"","text":"一个一直在琢磨着如何转行却在码农圈越陷越深的伪程序员为自己博客写的一篇前言。 27岁之前专注玩码 偶尔想想诗和远方 给自己的生活种种草，记得按时拔。 关于专业 Yaser Abu-Mostafa 深度学习（中/英） | Udacity GoodFellow Clean Code Thinking in Java Elm 算法 Spider 关于兴趣 英文语法书 朗读者","categories":[{"name":"开篇","slug":"开篇","permalink":"http://yoursite.com/categories/开篇/"}],"tags":[]}]}